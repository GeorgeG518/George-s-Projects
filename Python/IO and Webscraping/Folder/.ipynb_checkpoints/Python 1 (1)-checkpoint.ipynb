{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python 1 Assignment\n",
    "### Purpose: To explore different ways in which data can be brought in to Python via\n",
    "- Excel files\n",
    "- CSV files\n",
    "- Website data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring in standard libraries and set \"call\" name to ease access\n",
    "import pandas as pd\n",
    "\n",
    "# Set display to show up to 100 columns in dataframe\n",
    "pd.set_option('display.max_columns',100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Excel file into dataframe\n",
    "df_excel =  pd.ExcelFile('DataFinder Data Sample.xlsx') \n",
    "\n",
    "# Show worksheet names in dataframe from Excel file \n",
    "print(df_excel.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from specific worksheet into dataframe\n",
    "df_datafinder = df_excel.parse('______')\n",
    "\n",
    "# Show data in top two rows\n",
    "df_datafinder.head(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into dataframe\n",
    "df_titanic = pd.read_csv('Titanic Passenger data.csv', encoding=\"latin1\", index_col = None, header=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data in top five rows\n",
    "df_titanic.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Web Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library to read websites\n",
    "import urllib.request\n",
    "\n",
    "# Specify which URL/web page we are going to be scraping\n",
    "_____ = \"https://en.wikipedia.org/wiki/List_of_all-time_NFL_win%E2%80%93loss_records\"\n",
    "\n",
    "# Open the url using urllib.request and put the HTML into the page variable\n",
    "page = urllib.request.urlopen(_____)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the BeautifulSoup library so we can parse HTML and XML documents\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parse the HTML from the URL into the BeautifulSoup parse tree format\n",
    "soup = BeautifulSoup(page, \"lxml\")\n",
    "\n",
    "# Import the first table into a Python variable\n",
    "win_loss_table = soup.find('table', class_='wikitable sortable')\n",
    "\n",
    "# Show win-loss table in HTML\n",
    "win_loss_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list for each column in the table\n",
    "A=[]; B=[]; C=[]; D=[]; E=[]; F=[]; G=[]; H=[]; I=[]\n",
    "\n",
    "# We are going to ingore the headers in the <th> tags and create our own headers, but these could be imported too\n",
    "# Go through the rows in the table and put the contents in the appropriate list\n",
    "for row in win_loss_table.findAll('tr'):\n",
    "    cells=row.findAll('td')\n",
    "    if len(cells)==9:\n",
    "        A.append(cells[0].find(text=True))\n",
    "        B.append(cells[1].find(text=True))\n",
    "        C.append(cells[2].find(text=True))\n",
    "        D.append(cells[3].find(text=True))\n",
    "        E.append(cells[4].find(text=True))\n",
    "        F.append(cells[5].find(text=True))\n",
    "        G.append(cells[6].find(text=True))\n",
    "        H.append(cells[7].find(text=True))\n",
    "        I.append(cells[8].find(text=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame with our specific column headers and append the data from the lists under each header\n",
    "df_nfl = pd.DataFrame(data = A, columns=['Rank'])\n",
    "df_nfl['Team'] = B\n",
    "df_nfl['Games Played'] = C\n",
    "df_nfl['Games Won'] = D\n",
    "df_nfl['Games Lost'] = E\n",
    "df_nfl['Games Tied'] = F\n",
    "df_nfl['Percentage Won'] = G\n",
    "df_nfl['First NFL Season'] = H\n",
    "df_nfl['Team Division'] = I\n",
    "\n",
    "# Data comes in as objects (strings). Convert certain fields to numbers after removing commas\n",
    "df_nfl['Rank'] = pd.to_numeric(df_nfl['Rank'])\n",
    "df_nfl['Games Played'] = pd.to_numeric(df_nfl['Games Played'].str.replace(',', ''))\n",
    "df_nfl['Games Won'] = pd.to_numeric(df_nfl['Games Won'].str.replace(',', ''))\n",
    "df_nfl['Games Lost'] = pd.to_numeric(df_nfl['Games Lost'].str.replace(',', ''))\n",
    "df_nfl['Games Tied'] = pd.to_numeric(df_nfl['Games Tied'].str.replace(',', ''))\n",
    "df_nfl['Percentage Won'] = pd.to_numeric(df_nfl['Percentage Won'])\n",
    "df_nfl['First NFL Season'] = pd.to_numeric(df_nfl['First NFL Season'])\n",
    "\n",
    "# Reset index to rank field\n",
    "df_nfl.set_index('Rank', inplace=True)\n",
    "\n",
    "# Show current condition of dataframe fields\n",
    "df_nfl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 4 specific rows of data in the dataframe starting with row 5.  \n",
    "# Remember, Python starts at 0 not 1 in indexing rows.\n",
    "df_nfl[___:___]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Assignment 1\n",
    "### Name: Your Name Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_datafinder.sample(1)   # Shows a random sample of one row from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic.sample(1)   # Shows a random sample of one row from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nfl.sample(1)   # Shows a random sample of one row from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, socket\n",
    "print(datetime.datetime.now().isoformat())\n",
    "print(\"Your Computer Name is: \" + socket.gethostname())\n",
    "print(\"Your Computer IP Address is: \" + socket.gethostbyname(socket.gethostname()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
